{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VCOM-Proj2",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "SouyUWqrKJeu"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoeMGomes/VCOM-FEUP/blob/main/VCOM_Proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTULfSijJ8DO"
      },
      "source": [
        "# VCOM projects\n",
        "\n",
        "* Multiclass classification of images\n",
        "* Multilabel classification of images\n",
        "* Image detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2kPxLGnpsIU"
      },
      "source": [
        "## Colab data setup (mount drive and download to Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wf-KK7KtPd"
      },
      "source": [
        "### Mount to google drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epY5PVeLL-FI"
      },
      "source": [
        "How to check?\n",
        "1. open Files on the left side bar\n",
        "2. check if there is a folder called gdrive\n",
        "\n",
        "If not, run the following cells\n",
        "\n",
        "------------------\n",
        "\n",
        "Dataset available in [Kaggle](https://www.kaggle.com/c/imet-2019-fgvc6)\n",
        "\n",
        "Downloaded into [UP Google Drive](https://drive.google.com/drive/folders/16iBIVzeiW9DLSHXIpaK-vf1ZH05x9O23?usp=sharing)\n",
        "\n",
        "A shortcut to this folder needs to be added into the user's MyDrive folder in order to access the pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzN56B0Nq_kB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kqda0urZPK"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SouyUWqrKJeu"
      },
      "source": [
        "### Check the file navigation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1McAon2rc3P"
      },
      "source": [
        "\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLCWJG57JDf1"
      },
      "source": [
        "!pwd # should be ^^"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh3tdgGnxrLx"
      },
      "source": [
        "### Download data from Drive to Colab\n",
        "---\n",
        "To ease the utilization of images, the dataset is copied into this Colab Runtime. (Takes a few minutes to run)\n",
        "\n",
        "Use for Multiclass problem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCkVOUYRxqNO"
      },
      "source": [
        "driveDir = '/content/gdrive/My Drive/Kaggle/'\n",
        "newDir = '/content/proj/'\n",
        "import shutil\n",
        "import os\n",
        "if not os.path.exists(newDir):\n",
        "  os.mkdir(newDir)\n",
        "\n",
        "shutil.copy(driveDir+\"data.zip\", newDir+'data.zip', follow_symlinks=True)\n",
        "shutil.copy(driveDir+\"multilabel.csv\", newDir)\n",
        "shutil.copy(driveDir+\"vocabulary.py\", newDir)\n",
        "shutil.copy(driveDir+\"MultiThreadedLoader.py\" ,newDir)\n",
        "shutil.copy(driveDir+\"multiclass.csv\",newDir)\n",
        "shutil.unpack_archive(newDir+\"data.zip\",newDir)\n",
        "os.remove(newDir+\"data.zip\")\n",
        "\n",
        "os.chdir(newDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rHXKS71LrGV"
      },
      "source": [
        " Use for the Multi-Label Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgiZVMEg44gc"
      },
      "source": [
        "driveDir = '/content/gdrive/My Drive/Kaggle/'\n",
        "newDir = '/content/proj/'\n",
        "import shutil\n",
        "import os\n",
        "if not os.path.exists(newDir):\n",
        "  os.mkdir(newDir)\n",
        "\n",
        "shutil.copy(driveDir+\"multilabel.zip\", newDir)\n",
        "shutil.unpack_archive(newDir+\"multilabel.zip\",newDir)\n",
        "os.remove(newDir+\"multilabel.zip\")\n",
        "shutil.copy(driveDir+\"multilabel.csv\", newDir)\n",
        "shutil.copy(driveDir+\"vocabulary.py\", newDir)\n",
        "shutil.copy(driveDir+\"MultiThreadedLoader.py\" ,newDir)\n",
        "shutil.copy(driveDir+\"multiclass.csv\",newDir)\n",
        "\n",
        "os.chdir(newDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89FiW71nKkIg"
      },
      "source": [
        "### Test the file usage \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M3HSn-RvoQL"
      },
      "source": [
        "!ls data/ | grep 1a1e777b14d78e2c.png # should not return error, but the name of the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_C-_Hy4wBEZ"
      },
      "source": [
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow as show\n",
        "\n",
        "image = cv.imread('data/1a1e777b14d78e2c.png')\n",
        "show(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf0mOIzZLKRk"
      },
      "source": [
        "## Multiclass classification - Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sczaHks08SzM"
      },
      "source": [
        "### Treating data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp1hLFhg89nU"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "imgDir = 'data/'\n",
        "df = pd.read_csv('multiclass.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRciGwjjNsyC"
      },
      "source": [
        "#### Original dataset class distribution \n",
        "\n",
        "As it is visible here, the dataset is highly imbalanced, with some classes containing just 10 samples\n",
        "\n",
        "We can try to apply different techniques, explained below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n81iuasUHGqT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.attribute_ids.value_counts().plot(kind='bar', figsize=(12,3))\n",
        "plt.title(\"Number of images per label\")\n",
        "plt.ylabel('Number of images')\n",
        "plt.xlabel('Label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_TMXxlwZ86O"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "X = df.id.to_numpy().reshape(-1, 1)\n",
        "y = df.attribute_ids.to_numpy()\n",
        "\n",
        "print(Counter(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsTIvYxARnLA"
      },
      "source": [
        "##### Over-sampling \n",
        "\n",
        "Over-sampling is a method used in imbalanced dataset to balance it by duplicating (as many times as necessary) the least represented class(es)' examples.\n",
        "\n",
        "For this particular case, when the most frequent class has 9151 examples and the least frequents have 10, oversampling those 10 to 9151 leads to having particular examples repeated 900 times! (statistically, as this method is random) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrExGQBnSJbL"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample = RandomOverSampler(sampling_strategy='not majority')\n",
        "X_over, y_over = oversample.fit_resample(X, y)\n",
        "\n",
        "print(Counter(y_over))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO5PSbETXvq8"
      },
      "source": [
        "##### Under-sampling\n",
        "\n",
        "Opposed to over-sampling, under-sampling balances an imbalanced class distribution by randomly removing some examples of the most frequent class(es).\n",
        "\n",
        "This method is also not appropriate because all classes would be left with only 10 instances: without a reasonable amount of cases to work with, the training might suffer from under or over-fitting, not resulting in a good classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DacW0Ty_ZtRG"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "undersample = RandomUnderSampler(sampling_strategy='not minority')\n",
        "X_under, y_under = undersample.fit_resample(X, y)\n",
        "\n",
        "print(Counter(y_under))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSugLjrHOSoz"
      },
      "source": [
        "##### Joining classes\n",
        "\n",
        "As an alternative approach, our professor proposed us to translate this dataset into a 3-class distribution: class 13 (9151 examples), class 51 (7463) and all the remaining, joined into one (5473). This operation would be an intermediate step when the example belongs to one of the merged classes. In this case, after the initial classification, another classifier would be necessary to differ between those under-represented classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsQxmhQdOo5c"
      },
      "source": [
        "def joinLabels(row):\n",
        "  if row.attribute_ids == 13 or row.attribute_ids == 51:\n",
        "    return row.attribute_ids\n",
        "  else: \n",
        "    return 1\n",
        "\n",
        "df['joinedLabel'] = df.apply(lambda row: joinLabels(row), axis=1)\n",
        "df.joinedLabel.value_counts().plot(kind='bar', figsize=(5, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRhwbmRou44H"
      },
      "source": [
        "#### Applying the techniques in different ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lTjdE6S2Rwu"
      },
      "source": [
        "Here, the goal is to combine these above-refered techniques and trying to balance the dataset, depending on the chosen approach\n",
        "\n",
        "Previously, the classes RandomOverSampler and RandomUnderSampler were being used, and although they work as expected, they aren't quite useful for this use case, so we implemented our own:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x7RWmrI1Aw0"
      },
      "source": [
        "def os_us_to_value(df, value):\n",
        "  lst = []\n",
        "  for class_index, group in df.groupby('attribute_ids'):\n",
        "    if len(group) > value:\n",
        "      lst.append(group.sample(value, replace=True))\n",
        "    else:\n",
        "      lst.append(group)\n",
        "      lst.append(group.sample(value-len(group), replace=True))\n",
        "  return pd.concat(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sUpktY66M--"
      },
      "source": [
        "def os_us_to_value_bound(df, limit, bounds):\n",
        "  lst = []\n",
        "  for class_index, group in df.groupby('attribute_ids'):\n",
        "    size = len(group)\n",
        "    bound = bounds[0]\n",
        "    if size > limit:\n",
        "      bound = bounds[1]\n",
        "\n",
        "    if size < bound:\n",
        "      lst.append(group)\n",
        "      lst.append(group.sample(bound-size, replace=True))\n",
        "    else:\n",
        "      lst.append(group.sample(bound, replace=True))\n",
        "    \n",
        "  return pd.concat(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqVOyR1YvMjl"
      },
      "source": [
        "##### Over-sampling and Under-sampling to 200 examples each (OS&US-200)\n",
        "\n",
        "In the next cells, these functions are used in order to balance at around 200 examples per class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKg3Tw2rOZs_"
      },
      "source": [
        "osus200 = os_us_to_value(df, 200)\n",
        "osus200.attribute_ids.value_counts().plot(kind='bar', figsize=(12, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG1KX044PWBD"
      },
      "source": [
        "##### Over-sampling and Under-sampling to 500 examples each (OS&US-500)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmmRysS0Pyof"
      },
      "source": [
        "osus500 = os_us_to_value(df, 500)\n",
        "osus500.attribute_ids.value_counts().plot(kind='bar', figsize=(12, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glosMlb6P53q"
      },
      "source": [
        "##### 3-class approach (with OS and US) 3C-OS&US\n",
        "\n",
        "By just merging the least frequent classes, and having the merged set balanced with the other 2, it still doesn't fix the imbalanceness inside the 3rd class. So here, we are trying to balance both the 3-classes distribution, and the merged classes, at the same time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcqmO5ZuQMh7"
      },
      "source": [
        "osus3c = os_us_to_value_bound(df, 1000, (150, 7000))\n",
        "osus3c['merged3C'] = osus3c.apply(lambda row: joinLabels(row), axis=1)\n",
        "osus3c.merged3C.value_counts().plot(kind='bar', figsize=(5, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCIlViD-glBB"
      },
      "source": [
        "#### Splitting into training and testing datasets and Loading the images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot6YTgHEgrjb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_SIZE = 0.3\n",
        "train, test = train_test_split(osus200, test_size=TEST_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPwZV1_yNp_"
      },
      "source": [
        "from MultiThreadedLoader import LoadImagesToMemory\n",
        "\n",
        "# Loads every image into memory for easier use (avoids slow IO operations later on) \n",
        "train_imgs = []\n",
        "test_imgs = []\n",
        "\n",
        "train_list = train.id.unique()\n",
        "# Tuple list [(id,img),...]\n",
        "train_imgs = LoadImagesToMemory(imgDir,train_list,verbose=False) # Set verbose to true to print every loaded file path\n",
        "\n",
        "test_list = test.id.unique()\n",
        "# Tuple list [(id,img),...]\n",
        "test_imgs = LoadImagesToMemory(imgDir,test_list, verbose=False) # Set verbose to true to print every loaded file path \n",
        "\n",
        "train_df = pd.DataFrame(train_imgs, columns=['id','image'])\n",
        "test_df = pd.DataFrame(test_imgs, columns=['id','image'])\n",
        "\n",
        "# Dataframe (id, atribute_ids, joinedLabel, image)\n",
        "train_df = train.merge(train_df, how='left', on=\"id\")\n",
        "\n",
        "# Dataframe (id, atribute_ids, joinedLabel, image)\n",
        "test_df = test.merge(test_df, how='left', on=\"id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WufV1QkEPGhY"
      },
      "source": [
        "The **train_df** and **test_df** variables are the main data containers of this notebook. They will both contain id's, actual image data and attributes, descriptors, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tw0LtgQL-Av"
      },
      "source": [
        "Run this if RAM problems arise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xv3YaezK3rK"
      },
      "source": [
        "del train_imgs\n",
        "del test_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx1fdS_pfjFw"
      },
      "source": [
        "### Bag of Words\n",
        "The Bag of Words approach is actually very simple and straightforward.  \n",
        "For every image in the training dataset, descriptors of features are computed and added to a list. These descriptors are then clustered having so created a vocabulary for the training dataset (every cluster should correspond to a visual word)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I69TPbsOc8ZP"
      },
      "source": [
        "# detects descriptors in training dataset\n",
        "def addDescriptor(image_tuple):\n",
        "    keypoints, descriptors = detector.detectAndCompute(image_tuple[1], None)\n",
        "    return (image_tuple[0],descriptors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CmTB494fSdX"
      },
      "source": [
        "import multiprocessing \n",
        "import cv2 as cv\n",
        "detector = cv.KAZE_create() # Used to detect keypoints ans descriptors from an image\n",
        "\n",
        "# This solution utilizes multiprocessing to speed up the processing times\n",
        "# Unfortunately Google Colab only provides two computational cores\n",
        "cpu_count = multiprocessing.cpu_count()\n",
        "pool = multiprocessing.Pool(processes = cpu_count)\n",
        "descriptor_list = []\n",
        "\n",
        "print(\"CPU Cores:\",cpu_count)\n",
        "\n",
        "try:\n",
        "    descriptor_list = pool.map(addDescriptor, train_imgs)\n",
        "finally:\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eydSskIMvtBx"
      },
      "source": [
        "## Adds descriptors to train_df\n",
        "descriptors_df = pd.DataFrame(descriptor_list, columns=['id','descriptors'])\n",
        "train_df = pd.merge(train_df,descriptors_df, on=\"id\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YWcKCDIe33t"
      },
      "source": [
        "bowTrainer = cv.BOWKMeansTrainer(100) # Used to cluster descriptors \n",
        "\n",
        "# Adds found descriptors to Trainer Object\n",
        "for index, row in train_df.iterrows():\n",
        "  if row[\"descriptors\"] is not None:\n",
        "      bowTrainer.add(row[\"descriptors\"])\n",
        "\n",
        "vocabulary = bowTrainer.cluster()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPr-Cfsh7tO8"
      },
      "source": [
        "Creating Histograms and Standardization of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qla27GFE7yeQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster.vq import vq\n",
        "import numpy as np\n",
        "\n",
        "## Creates an \"histogram\"/feature count list for each image\n",
        "histograms_list = np.zeros((len(train_df),100),\"float32\")\n",
        "for index,row in train_df.iterrows(): \n",
        "    if row[\"descriptors\"] is not None:\n",
        "        words,distance= vq(row[\"descriptors\"],vocabulary)\n",
        "        for w in words:\n",
        "            histograms_list[index][w]+=1\n",
        "\n",
        "## Standardizes the features range as z = (x - u)/s \n",
        "## Where x is the actual value, u is the mean and s is the standard deviation\n",
        "standardized_range = StandardScaler().fit(histograms_list)\n",
        "histograms_list= standardized_range.transform(histograms_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6vgViW191zO"
      },
      "source": [
        "Classification model with SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmnInRF096r6"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf=LinearSVC(max_iter=1000)\n",
        "clf.fit(histograms_list,np.array(train_df.attribute_ids)) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOfEnLVdjSTj"
      },
      "source": [
        "descriptor_list_test=[]\n",
        "\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    keypoints, descriptors = detector.detectAndCompute(row.image, None)\n",
        "\n",
        "    descriptor_list_test.append((row.id,descriptors))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-vzuL8DwRmM"
      },
      "source": [
        "## Adds descriptors to test_df\n",
        "descriptors_test_df = pd.DataFrame(descriptor_list_test, columns=['id','descriptors'])\n",
        "test_df = pd.merge(test_df,descriptors_test_df, on=\"id\")\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT5hLKSokHVC"
      },
      "source": [
        "from scipy.cluster.vq import vq\n",
        "\n",
        "## Creates an \"histogram\"/feature count list for each image\n",
        "histogram_test_list = np.zeros((len(descriptor_list_test),100),\"float32\")\n",
        "for index,row in test_df.iterrows(): \n",
        "    if row[\"descriptors\"] is not None:\n",
        "        words,distance= vq(row[\"descriptors\"],vocabulary) \n",
        "        for w in words:\n",
        "            histogram_test_list[index][w]+=1\n",
        "\n",
        "standardized_test_features = standardized_range.transform(histogram_test_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ns3WUU5wE18"
      },
      "source": [
        "#### Get Results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FvpBma0q7J"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,plot_confusion_matrix,fbeta_score, recall_score, precision_score\n",
        "predictions = clf.predict(standardized_test_features)\n",
        "\n",
        "accuracy = accuracy_score(test_df.attribute_ids.values, predictions)\n",
        "recall = recall_score(test_df.attribute_ids.values, predictions, average=\"macro\")\n",
        "precision= precision_score(test_df.attribute_ids.values, predictions, average=\"macro\")\n",
        "fscore = fbeta_score(test_df.attribute_ids.values, predictions,average=\"macro\", beta=2)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plot_confusion_matrix(clf, standardized_test_features, test_df.attribute_ids.values)\n",
        "\n",
        "plt.show()\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Recall:\",recall)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"F2 Score:\",fscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAzVFSgOX70U"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jLW2AKNFGH"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C3M33KfYC7y"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_df.image[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpRWYXdGbTrC"
      },
      "source": [
        "labels = train_df.attribute_ids.unique() # with osus200 and osus500\n",
        "# labels = train_df.merged3C.unique() # with osus3C\n",
        "def id2Label(row):\n",
        "  return np.where(labels==row.attribute_ids)[0][0] #osus200 and osus500\n",
        "  # return np.where(labels==row.merged3C)[0][0] # osus3c\n",
        "\n",
        "train_df[\"label\"] = train_df.apply(lambda row: id2Label(row), axis=1)\n",
        "test_df[\"label\"] = test_df.apply(lambda row: id2Label(row), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNCfMSILbwrA"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), input_shape=(300,300,1), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(labels.size, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0hkLDCOb333"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(np.concatenate(train_df.image).reshape((-1, 300, 300 ,1)), train_df.label, epochs=200, validation_split=0.1)\n",
        "print(history.history)\n",
        "\n",
        "y_pred = model.predict(np.concatenate(test_df.image).reshape((-1, 300, 300 ,1)), batch_size=32, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds496NrscAX_"
      },
      "source": [
        "## PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,plot_confusion_matrix,fbeta_score, recall_score, precision_score\n",
        "\n",
        "accuracy = accuracy_score(test_df.label, y_pred_bool)\n",
        "recall = recall_score(test_df.label, y_pred_bool, average=\"macro\")\n",
        "precision= precision_score(test_df.label, y_pred_bool, average=\"macro\")\n",
        "fscore = fbeta_score(test_df.label, y_pred_bool,average=\"macro\", beta=2)\n",
        "\n",
        "# TODO: get other measurements\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Recall:\",recall)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"F2 Score:\",fscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR5wws2YUC6Z"
      },
      "source": [
        "## Multilabel classification - Task 2 Option 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdQxPAkWQ5F3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "imgDir = 'data/'\n",
        "df = pd.read_csv('multilabel.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jazt1LcUT9iJ"
      },
      "source": [
        "shutil.copy(driveDir+\"multilabel.csv\", newDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbEM3AzRDLF"
      },
      "source": [
        "df.loc[df[\"id\"]== \"1fad69ed268ac538\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aqveQ09eBp_"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "def convert2List(row):\n",
        "  return row.attribute_ids.split(' ')\n",
        "\n",
        "df['label'] = df.apply(lambda row: convert2List(row), axis=1)\n",
        "one_hot = MultiLabelBinarizer()\n",
        "df['one_hot'] = list(one_hot.fit_transform(df.label))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyYLcVAkRYqV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_SIZE = 0.3\n",
        "train, test = train_test_split(df, test_size=TEST_SIZE)\n",
        "print(len(train))\n",
        "print(len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrpx7Uib8pmj"
      },
      "source": [
        "import glob\n",
        "\n",
        "all_images = glob.glob('data/*.png')\n",
        "train_ids = train.id.values\n",
        "test_ids = test.id.values\n",
        "train_both = [x for x in train_ids if 'data/' + x +'.png' in all_images]\n",
        "test_both = [x for x in test_ids if 'data/' + x +'.png' in all_images]\n",
        "\n",
        "print(len(train_both), len(test_both), len(all_images) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw4siUHkRcDE"
      },
      "source": [
        "from MultiThreadedLoader import LoadImagesToMemory\n",
        "\n",
        "# Loads every image into memory for easier use (avoids slow IO operations later on) \n",
        "train_imgs = []\n",
        "test_imgs = []\n",
        "\n",
        "train_list = train.id.unique()\n",
        "# Tuple list [(id,img),...]\n",
        "train_imgs = LoadImagesToMemory(imgDir,train_both,verbose=False) # Set verbose to true to print every loaded file path\n",
        "\n",
        "test_list = test.id.unique()\n",
        "# Tuple list [(id,img),...]\n",
        "test_imgs = LoadImagesToMemory(imgDir,test_both, verbose=False) # Set verbose to true to print every loaded file path \n",
        "\n",
        "train_df = pd.DataFrame(train_imgs, columns=['id','image'])\n",
        "test_df = pd.DataFrame(test_imgs, columns=['id','image'])\n",
        "print(train_df.shape)\n",
        "# Dataframe (id, atribute_ids, joinedLabel, image)\n",
        "train_df = train_df.merge(train, how='left', on=\"id\")\n",
        "\n",
        "# Dataframe (id, atribute_ids, joinedLabel, image)\n",
        "test_df = test_df.merge(test, how='left', on=\"id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxDnFbStiK8v"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS4_1duoiYZb"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), input_shape=(300,300,1), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(len(df.one_hot[0]), activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpWPYnkOiiui"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def f2_score(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, \"int32\")\n",
        "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
        "    y_correct = y_true * y_pred\n",
        "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
        "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
        "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
        "    precision = sum_correct / sum_pred\n",
        "    recall = sum_correct / sum_true\n",
        "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
        "    f_score = tf.where(tf.math.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return tf.reduce_mean(f_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TXTI5EUibtv"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['acc',f1_m,precision_m, recall_m, f2_score])\n",
        "\n",
        "history = model.fit(np.concatenate(train_df.image).reshape((-1, 300, 300 ,1)), pd.DataFrame(np.concatenate(train_df.one_hot.values).reshape(-1, len(df.one_hot[0]))), epochs=100, validation_split=0.1)\n",
        "\n",
        "print(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amOZy7UgeSog"
      },
      "source": [
        "## PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,plot_confusion_matrix,fbeta_score, recall_score, precision_score\n",
        "\n",
        "predictions = model.predict(np.concatenate(test_df.image).reshape((-1, 300, 300 ,1)), batch_size=32, verbose=1)\n",
        "y_pred = (predictions > 0.5) \n",
        "y_pred_bool = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "accuracy = accuracy_score(pd.DataFrame(np.concatenate(test_df.one_hot.values).reshape(-1, len(df.one_hot[0]))), y_pred)\n",
        "recall = recall_score(pd.DataFrame(np.concatenate(test_df.one_hot.values).reshape(-1, len(df.one_hot[0]))), y_pred, average=\"macro\")\n",
        "precision= precision_score(pd.DataFrame(np.concatenate(test_df.one_hot.values).reshape(-1, len(df.one_hot[0]))), y_pred, average=\"macro\")\n",
        "fscore = fbeta_score(pd.DataFrame(np.concatenate(test_df.one_hot.values).reshape(-1, len(df.one_hot[0]))), y_pred,average=\"macro\", beta=2)\n",
        "\n",
        "# TODO: get other measurements\n",
        "print(\"Accuracy:\",accuracy)\n",
        "print(\"Recall:\",recall)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"F2 Score:\",fscore)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}